⑴「順伝播」
・入力データをネットワークに通して、出力値を得る

[全結合層の場合]

1.線形変換

・入力データ×重み＋バイアス

2.シグモイド関数

・シグモイド関数の引数に(入力データ×重み＋バイアス)を代入

3.損失関数を求める
・損失関数に順伝播の出力値を代入し、損失を求める

1.入力層から隠れ層へ
2.隠れ層から出力層へ
3.最終的な出力を得る

⑵「逆伝播」
・順伝播の後、出力と正解ラベルの誤差を計算し、
　その誤差をネットワークの各層に遡って伝播させる

誤差を逆伝播し、合成関数の微分の性質で重みの勾配を求める
（損失関数を重みに対して微分した値）
損失を出力で微分した値×出力をシグモイド関数の値で微分した値×活性化関数を線形変換の値で微分した値

（隠れ層の誤差）
出力層の損失に活性化関数の出力値で微分した値×重み(隠れ層→出力層)

（隠れ層を重みで微分した値）
隠れ層の誤差を活性化関数の出力で微分した値×隠れ層の活性化関数を線形変換で微分した値×線形変換を隠れ層の重みで微分した値

1.誤差(損失)を計算
2.誤差を出力層から入力層へ逆伝播
3.重みを更新：逆伝播で求めた勾配を元に、パラメータを更新。

⑶バッチ処理と早期終了

バッチ処理　→　データをまとめてではなく、バッチ単位に分けて学習をする。

バッチ数が64で、エポック数が100の場合、全データを64個に分けて、データの数繰り返して学習するプロセスを100回行う
1エポックの学習が終了したら、検証データで順伝播を行い損失が指定回数連続で減少しなかったら学習を終了させる。

